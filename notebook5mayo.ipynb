{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_list, struct\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "import codecs\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = spark.read.json('sample_10e3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----------+--------------+-------------+----------------+-----------+--------------------+--------------------+---------+--------+\n",
      "|                 _id|ageRange|idplug_base|idplug_station|idunplug_base|idunplug_station|travel_time|     unplug_hourTime|       user_day_code|user_type|zip_code|\n",
      "+--------------------+--------+-----------+--------------+-------------+----------------+-----------+--------------------+--------------------+---------+--------+\n",
      "|{5cf83b752f3843a0...|       0|         21|            66|            8|              90|        219|{2019-06-01T00:00...|e4d55deb9ac172a8d...|        1|        |\n",
      "|{5cf83b762f3843a0...|       4|         19|           136|           19|              71|        359|{2019-06-01T00:00...|8a0c4123e924a50a9...|        1|   28039|\n",
      "|{5cf83b762f3843a0...|       4|         17|            38|            7|              39|        375|{2019-06-01T00:00...|a6a9c1f74a6849600...|        1|   28013|\n",
      "|{5cf83b762f3843a0...|       5|          4|            90|           21|              66|        264|{2019-06-01T00:00...|5706c0bd494acc022...|        1|   28009|\n",
      "|{5cf83b762f3843a0...|       4|          3|           166|           13|             152|        367|{2019-06-01T00:00...|eb1b6d32bd4add5d5...|        1|   28006|\n",
      "|{5cf83b762f3843a0...|       5|         14|            53|            4|              55|        174|{2019-06-01T00:00...|c2905f6038aa9523d...|        1|   28907|\n",
      "|{5cf83b762f3843a0...|       0|          2|           129|            6|             133|        308|{2019-06-01T00:00...|f94420744ea060ac4...|        1|        |\n",
      "|{5cf83b762f3843a0...|       4|         21|           169|            3|             153|        462|{2019-06-01T00:00...|e75471af2ea032a32...|        1|   28003|\n",
      "|{5cf83b762f3843a0...|       0|         24|           129|           14|              44|        482|{2019-06-01T00:00...|c0d73ee753773a3bf...|        1|        |\n",
      "|{5cf83b762f3843a0...|       4|         11|           133|           21|              85|        480|{2019-06-01T00:00...|47ecd557f21ca7aee...|        1|   28004|\n",
      "|{5cf83b762f3843a0...|       5|          2|            83|           18|              31|        546|{2019-06-01T00:00...|87ccc3f59b45ef261...|        1|   28007|\n",
      "|{5cf83b762f3843a0...|       0|          7|            53|           15|              38|        519|{2019-06-01T00:00...|05bd8e0842cbfadb8...|        1|        |\n",
      "|{5cf83b762f3843a0...|       4|         24|            13|           17|             118|        374|{2019-06-01T00:00...|812870450df33ac5c...|        1|   39316|\n",
      "|{5cf83b762f3843a0...|       4|         13|            10|            9|              27|        188|{2019-06-01T00:00...|c828f824a86378bf0...|        1|   28012|\n",
      "|{5cf83b762f3843a0...|       4|          2|            74|           20|              90|        133|{2019-06-01T00:00...|538fc94c0d298f7ee...|        1|   28045|\n",
      "|{5cf83b762f3843a0...|       0|         17|            54|           21|             100|        514|{2019-06-01T00:00...|53a9f79ec4c6d60c2...|        1|        |\n",
      "|{5cf83b762f3843a0...|       4|         12|            83|            5|              67|        517|{2019-06-01T00:00...|b27886fecd2db0f3c...|        1|   28008|\n",
      "|{5cf83b762f3843a0...|       4|          5|            83|            3|              67|        525|{2019-06-01T00:00...|eee03ef92db2fe559...|        1|   28019|\n",
      "|{5cf83b762f3843a0...|       0|          9|           163|            5|              63|        351|{2019-06-01T00:00...|b61ef9ebd0342c431...|        1|        |\n",
      "|{5cf83b762f3843a0...|       0|         22|            84|            7|              42|        483|{2019-06-01T00:00...|01bf069d0732b2b01...|        1|        |\n",
      "+--------------------+--------+-----------+--------------+-------------+----------------+-----------+--------------------+--------------------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|ageRange|travel_time|\n",
      "+--------+-----------+\n",
      "|       0|        219|\n",
      "|       4|        359|\n",
      "|       4|        375|\n",
      "|       5|        264|\n",
      "|       4|        367|\n",
      "|       5|        174|\n",
      "|       0|        308|\n",
      "|       4|        462|\n",
      "|       0|        482|\n",
      "|       4|        480|\n",
      "|       5|        546|\n",
      "|       0|        519|\n",
      "|       4|        374|\n",
      "|       4|        188|\n",
      "|       4|        133|\n",
      "|       0|        514|\n",
      "|       4|        517|\n",
      "|       4|        525|\n",
      "|       0|        351|\n",
      "|       0|        483|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = df.drop('_id','unplug_hourTime','idplug_base','idunplug_base','track','idplug_station','idunplug_station','idunplug_station','user_day_code','user_type','zip_code')\n",
    "df = df0\n",
    "df = df.select('ageRange','travel_time')\n",
    "df.show()\n",
    "# to fit df in page and see more clearly the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|ageRange|travel_time|\n",
      "+--------+-----------+\n",
      "|       0|        219|\n",
      "|       4|        359|\n",
      "|       4|        375|\n",
      "|       5|        264|\n",
      "|       4|        367|\n",
      "|       5|        174|\n",
      "|       0|        308|\n",
      "|       4|        462|\n",
      "|       0|        482|\n",
      "|       4|        480|\n",
      "|       5|        546|\n",
      "|       0|        519|\n",
      "|       4|        374|\n",
      "|       4|        188|\n",
      "|       4|        133|\n",
      "|       0|        514|\n",
      "|       4|        517|\n",
      "|       4|        525|\n",
      "|       0|        351|\n",
      "|       0|        483|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+--------------------+\n",
      "|ageRange|       lista_tiempos|\n",
      "+--------+--------------------+\n",
      "|       0|[219, 308, 482, 5...|\n",
      "|       1|[1146, 1150, 1151...|\n",
      "|       2|[466, 404, 210, 1...|\n",
      "|       3|[477, 574, 435, 7...|\n",
      "|       4|[359, 375, 367, 4...|\n",
      "|       5|[264, 174, 546, 6...|\n",
      "|       6|[1036, 1108, 1111...|\n",
      "+--------+--------------------+\n",
      "\n",
      "+--------+--------------------+------------------+\n",
      "|ageRange|       lista_tiempos|     media_tiempos|\n",
      "+--------+--------------------+------------------+\n",
      "|       0|[219, 308, 482, 5...| 947.0936863543789|\n",
      "|       1|[1146, 1150, 1151...|1092.8947368421052|\n",
      "|       2|[466, 404, 210, 1...| 675.1666666666666|\n",
      "|       3|[477, 574, 435, 7...| 826.9466666666667|\n",
      "|       4|[359, 375, 367, 4...| 897.1685393258427|\n",
      "|       5|[264, 174, 546, 6...| 792.8702290076336|\n",
      "|       6|[1036, 1108, 1111...|             982.8|\n",
      "+--------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# APARTADO 1: Tiempo que una persona está en la bici en función de su grupo de edad.\n",
    "\n",
    "# intentos fallidos con lo de carmona\n",
    "#df.groupBy('ageRange').agg({'travel_time':'sum'}).show()\n",
    "#unos = udf(lambda x: 1, IntegerType())\n",
    "#df1 = df\n",
    "#df1.select(unos('ageRange'))\n",
    "#df = df.withColumn('contador', unos(df1['ageRange']))\n",
    "\n",
    "df.show()\n",
    "media = udf (lambda lista: sum(lista)/len(lista))\n",
    "df = df.groupBy('ageRange').agg(collect_list('travel_time').alias('lista_tiempos')).sort('ageRange')\n",
    "df.show()\n",
    "df.withColumn('media_tiempos', media(df['lista_tiempos'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+----------------+\n",
      "|zip_code|idplug_station|idunplug_station|\n",
      "+--------+--------------+----------------+\n",
      "|   28039|           136|              71|\n",
      "|   28013|            38|              39|\n",
      "|   28009|            90|              66|\n",
      "|   28006|           166|             152|\n",
      "|   28907|            53|              55|\n",
      "|   28003|           169|             153|\n",
      "|   28004|           133|              85|\n",
      "|   28007|            83|              31|\n",
      "|   39316|            13|             118|\n",
      "|   28012|            10|              27|\n",
      "|   28045|            74|              90|\n",
      "|   28008|            83|              67|\n",
      "|   28019|            83|              67|\n",
      "|   28028|           171|              77|\n",
      "|   28029|           151|              99|\n",
      "|   28006|             5|             156|\n",
      "|   28006|             5|             156|\n",
      "|   28010|             5|             156|\n",
      "|   28026|           135|              31|\n",
      "|   28007|            94|             130|\n",
      "+--------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# APARTADO 2: Barrios con más salidas y llegadas. \n",
    "df = df0\n",
    "df = df.select('zip_code','idplug_station','idunplug_station').filter(col('zip_code')!= '')\n",
    "df.show()\n",
    "# sería con esto, pero hay q mirar q estaciones estan en el mismo barrio....\n",
    "# zip code es el codigo postal del usuario q realiza el movimiento....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|zip_code|hora|\n",
      "+--------+----+\n",
      "|   28039|   0|\n",
      "|   28013|   0|\n",
      "|   28009|   0|\n",
      "|   28006|   0|\n",
      "|   28907|   0|\n",
      "|   28003|   0|\n",
      "|   28004|   0|\n",
      "|   28007|   0|\n",
      "|   39316|   0|\n",
      "|   28012|   0|\n",
      "|   28045|   0|\n",
      "|   28008|   0|\n",
      "|   28019|   0|\n",
      "|   28028|   0|\n",
      "|   28029|   0|\n",
      "|   28006|   0|\n",
      "|   28006|   0|\n",
      "|   28010|   0|\n",
      "|   28026|   0|\n",
      "|   28007|   0|\n",
      "+--------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+--------------------+\n",
      "|zip_code|         lista_horas|\n",
      "+--------+--------------------+\n",
      "|   06800|                 [0]|\n",
      "|    2008|              [0, 1]|\n",
      "|   28001|[0, 0, 0, 0, 0, 1...|\n",
      "|   28002|  [0, 0, 0, 0, 0, 1]|\n",
      "|   28003|[0, 0, 0, 0, 0, 0...|\n",
      "|   28004|[0, 0, 0, 0, 0, 0...|\n",
      "|   28005|[0, 0, 0, 0, 0, 0...|\n",
      "|   28006|[0, 0, 0, 0, 0, 0...|\n",
      "|   28007|[0, 0, 0, 0, 0, 0...|\n",
      "|   28008|[0, 0, 0, 0, 0, 0...|\n",
      "|   28009|[0, 0, 0, 0, 0, 0...|\n",
      "|   28010|[0, 0, 0, 0, 0, 0...|\n",
      "|   28011|              [0, 1]|\n",
      "|   28012|[0, 0, 0, 0, 0, 0...|\n",
      "|   28013|[0, 0, 0, 0, 0, 0...|\n",
      "|   28014|[0, 0, 0, 0, 0, 1...|\n",
      "|   28015|[0, 0, 0, 0, 0, 0...|\n",
      "|   28016|        [0, 0, 0, 1]|\n",
      "|   28017|        [0, 0, 0, 0]|\n",
      "|   28018|              [0, 1]|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"<ipython-input-271-e3f6d3c3f177>\", line 12, in <lambda>\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-e3f6d3c3f177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmedia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlista\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hora_media'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lista_horas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"<ipython-input-271-e3f6d3c3f177>\", line 12, in <lambda>\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n"
     ]
    }
   ],
   "source": [
    "# APARTADO 3. Horas en las que hay más desenganches de bici en función del barrio y del tiempo que viajan.\n",
    "# lo hago en funcion del barrio, en funcion del tiempo es analogo\n",
    "\n",
    "\n",
    "# problema: no sé convertir la hora a un entero\n",
    "\n",
    "import struct\n",
    "df = df0\n",
    "df = df.select('zip_code','unplug_hourTime').filter(col('zip_code')!= '')\n",
    "hora = udf(lambda x: int(str(x)[23]) if str(x)[22]== '0' else int(str(x)[22]+str(x)[23])) # por lo visto no salen enteros\n",
    "df = df.withColumn('hora', hora(df['unplug_hourTime'])).drop('unplug_hourTime')\n",
    "#print(df.dtypes)\n",
    "df.show()\n",
    "df = df.groupBy('zip_code').agg(collect_list('hora').alias('lista_horas')).sort('zip_code')\n",
    "df.show()\n",
    "media = udf (lambda lista: sum(lista)/len(lista))\n",
    "df.withColumn('hora_media', media(df['lista_horas'])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'groupBy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-9cd56713e006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_trips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_day_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_trips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'groupBy'"
     ]
    }
   ],
   "source": [
    "#3\n",
    "df_trips = df1.groupBy('user_day_code').count()\n",
    "df_trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips.filter(df_trips['count']==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'user_day_code' given input columns: [ageRange, contador, travel_time];\n'Aggregate ['user_day_code], ['user_day_code, count(1) AS count#2266L]\n+- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2192]\n   +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2181]\n      +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2144]\n         +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2080]\n            +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2043]\n               +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2035]\n                  +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#1996]\n                     +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#1985]\n                        +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#1946]\n                           +- Project [ageRange#972L, travel_time#977L]\n                              +- Project [_id#971, ageRange#972L, travel_time#977L]\n                                 +- Relation [_id#971,ageRange#972L,idplug_base#973L,idplug_station#974L,idunplug_base#975L,idunplug_station#976L,travel_time#977L,unplug_hourTime#978,user_day_code#979,user_type#980L,zip_code#981] json\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-27a0b8f7227d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#lo mismo en una línea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_day_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trips'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trips.count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36m_api\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'user_day_code' given input columns: [ageRange, contador, travel_time];\n'Aggregate ['user_day_code], ['user_day_code, count(1) AS count#2266L]\n+- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2192]\n   +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2181]\n      +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2144]\n         +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2080]\n            +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2043]\n               +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#2035]\n                  +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#1996]\n                     +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#1985]\n                        +- Project [ageRange#972L, travel_time#977L, <lambda>(ageRange#972L) AS contador#1946]\n                           +- Project [ageRange#972L, travel_time#977L]\n                              +- Project [_id#971, ageRange#972L, travel_time#977L]\n                                 +- Relation [_id#971,ageRange#972L,idplug_base#973L,idplug_station#974L,idunplug_base#975L,idunplug_station#976L,travel_time#977L,unplug_hourTime#978,user_day_code#979,user_type#980L,zip_code#981] json\n"
     ]
    }
   ],
   "source": [
    "#lo mismo en una línea\n",
    "from pyspark.sql.functions import col\n",
    "df1.groupBy('user_day_code').count().alias('trips').filter(col('trips.count')==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|count|count|\n",
      "+-----+-----+\n",
      "|    1|  873|\n",
      "|    3|    1|\n",
      "|    2|   39|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4. Histograma de viajes\n",
    "df1.groupBy('user_day_code').count().groupBy('count').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|trip_number|count|\n",
      "+-----------+-----+\n",
      "|          1|  873|\n",
      "|          3|    1|\n",
      "|          2|   39|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('user_day_code').count().withColumnRenamed('count','trip_number').\\\n",
    "    groupBy('trip_number').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Return trip. \n",
    "\n",
    "#En las celdas anteriores, vemos que al agrupar perdemos la información.  \n",
    "#se echa de menos el poder trabajar con los datos agregados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------------------------------+\n",
      "|       user_day_code|collect_list(struct(idunplug_station, idplug_station))|\n",
      "+--------------------+------------------------------------------------------+\n",
      "|003a61da2de58f96b...|                                             [{9, 16}]|\n",
      "|004b59e8e915fea89...|                                          [{171, 106}]|\n",
      "|00c762bdd28e33ad6...|                                            [{19, 90}]|\n",
      "|00e51402a96f66595...|                                            [{26, 79}]|\n",
      "|01232b2ca4316d5a8...|                                           [{12, 174}]|\n",
      "|015d7f04c3112bc80...|                                           [{174, 31}]|\n",
      "|016def195d7b6e1f9...|                                           [{156, 63}]|\n",
      "|0171f8de1acd7d8c7...|                                            [{62, 82}]|\n",
      "|017cc6f6baa1d23a0...|                                            [{88, 54}]|\n",
      "|019909d2442ab142c...|                                            [{90, 82}]|\n",
      "|01afe1971a4a4fa91...|                                            [{76, 81}]|\n",
      "|01bf069d0732b2b01...|                                            [{42, 84}]|\n",
      "|01ce39793f7b766e3...|                                          [{169, 149}]|\n",
      "|0247f880037914475...|                                            [{84, 57}]|\n",
      "|02cb8492c91c06764...|                                           [{169, 26}]|\n",
      "|02f00ebaf4701793d...|                                            [{90, 82}]|\n",
      "|0382218c6e10772dc...|                                   [{45, 71}, {71, 8}]|\n",
      "|039ae0fa68bc44bf0...|                                          [{111, 155}]|\n",
      "|03d3c2c2df2d08e0f...|                                           [{135, 51}]|\n",
      "|0444abbe992567898...|                                            [{38, 52}]|\n",
      "+--------------------+------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, struct\n",
    "dfg = df.groupBy('user_day_code').agg(collect_list(struct('idunplug_station','idplug_station')))\n",
    "dfg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|       user_day_code|             result|\n",
      "+--------------------+-------------------+\n",
      "|003a61da2de58f96b...|          [{9, 16}]|\n",
      "|004b59e8e915fea89...|       [{171, 106}]|\n",
      "|00c762bdd28e33ad6...|         [{19, 90}]|\n",
      "|00e51402a96f66595...|         [{26, 79}]|\n",
      "|01232b2ca4316d5a8...|        [{12, 174}]|\n",
      "|015d7f04c3112bc80...|        [{174, 31}]|\n",
      "|016def195d7b6e1f9...|        [{156, 63}]|\n",
      "|0171f8de1acd7d8c7...|         [{62, 82}]|\n",
      "|017cc6f6baa1d23a0...|         [{88, 54}]|\n",
      "|019909d2442ab142c...|         [{90, 82}]|\n",
      "|01afe1971a4a4fa91...|         [{76, 81}]|\n",
      "|01bf069d0732b2b01...|         [{42, 84}]|\n",
      "|01ce39793f7b766e3...|       [{169, 149}]|\n",
      "|0247f880037914475...|         [{84, 57}]|\n",
      "|02cb8492c91c06764...|        [{169, 26}]|\n",
      "|02f00ebaf4701793d...|         [{90, 82}]|\n",
      "|0382218c6e10772dc...|[{45, 71}, {71, 8}]|\n",
      "|039ae0fa68bc44bf0...|       [{111, 155}]|\n",
      "|03d3c2c2df2d08e0f...|        [{135, 51}]|\n",
      "|0444abbe992567898...|         [{38, 52}]|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfg = df.groupBy('user_day_code').\\\n",
    "    agg(collect_list(struct('idunplug_station','idplug_station')).alias('result'))\n",
    "dfg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicar la función de abajo...para calcular la longitud... ver si podemos hacer más cosas, como ver \n",
    "# que es un round trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|<lambda>(user_day_code)|\n",
      "+-----------------------+\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "|                     64|\n",
      "+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "trips_len = udf(lambda x: len(x), IntegerType())\n",
    "dfg.select(trips_len('user_day_code')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------+\n",
      "|       user_day_code|             result|len_udc|\n",
      "+--------------------+-------------------+-------+\n",
      "|003a61da2de58f96b...|          [{9, 16}]|     64|\n",
      "|004b59e8e915fea89...|       [{171, 106}]|     64|\n",
      "|00c762bdd28e33ad6...|         [{19, 90}]|     64|\n",
      "|00e51402a96f66595...|         [{26, 79}]|     64|\n",
      "|01232b2ca4316d5a8...|        [{12, 174}]|     64|\n",
      "|015d7f04c3112bc80...|        [{174, 31}]|     64|\n",
      "|016def195d7b6e1f9...|        [{156, 63}]|     64|\n",
      "|0171f8de1acd7d8c7...|         [{62, 82}]|     64|\n",
      "|017cc6f6baa1d23a0...|         [{88, 54}]|     64|\n",
      "|019909d2442ab142c...|         [{90, 82}]|     64|\n",
      "|01afe1971a4a4fa91...|         [{76, 81}]|     64|\n",
      "|01bf069d0732b2b01...|         [{42, 84}]|     64|\n",
      "|01ce39793f7b766e3...|       [{169, 149}]|     64|\n",
      "|0247f880037914475...|         [{84, 57}]|     64|\n",
      "|02cb8492c91c06764...|        [{169, 26}]|     64|\n",
      "|02f00ebaf4701793d...|         [{90, 82}]|     64|\n",
      "|0382218c6e10772dc...|[{45, 71}, {71, 8}]|     64|\n",
      "|039ae0fa68bc44bf0...|       [{111, 155}]|     64|\n",
      "|03d3c2c2df2d08e0f...|        [{135, 51}]|     64|\n",
      "|0444abbe992567898...|         [{38, 52}]|     64|\n",
      "+--------------------+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfg2 = dfg.withColumn('len_udc', trips_len(dfg['user_day_code']))\n",
    "dfg2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|       user_day_code|              result|round_trip|\n",
      "+--------------------+--------------------+----------+\n",
      "|13b9c8b5ffecc4d2a...|[{125, 6}, {6, 125}]|      true|\n",
      "|6fb07b5e128af9a6b...|[{57, 19}, {19, 57}]|      true|\n",
      "|a1e5829f6bb2030d7...|[{129, 57}, {57, ...|      true|\n",
      "|b10c476e28ef97b3f...|[{96, 114}, {114,...|      true|\n",
      "|bcef457f1234cc899...|[{96, 114}, {114,...|      true|\n",
      "|f7f4cd3b9b0f8c51b...|[{62, 169}, {169,...|      true|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "def round_trip(x):\n",
    "    if len(x) != 2:\n",
    "        return False\n",
    "    else:\n",
    "        return x[0][1] == x[1][0] and x[0][0] == x[1][1]\n",
    "\n",
    "round_trip_udf = udf(lambda x: round_trip(x), BooleanType())\n",
    "\n",
    "dfg.withColumn('round_trip', round_trip_udf(dfg['result'])).alias('dfgrt').filter(col('dfgrt.round_trip')).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
